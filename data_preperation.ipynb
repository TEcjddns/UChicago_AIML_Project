{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26993"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/Capgemini_Employee_Reviews_from_AmbitionBox.csv')\n",
    "\n",
    "df.head()\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26993 entries, 0 to 26992\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Title                25913 non-null  object \n",
      " 1   Place                24597 non-null  object \n",
      " 2   Job_type             11556 non-null  object \n",
      " 3   Department           22083 non-null  object \n",
      " 4   Date                 25915 non-null  object \n",
      " 5   Overall_rating       25898 non-null  float64\n",
      " 6   work_life_balance    26977 non-null  float64\n",
      " 7   skill_development    26976 non-null  float64\n",
      " 8   salary_and_benefits  26947 non-null  float64\n",
      " 9   job_security         26943 non-null  float64\n",
      " 10  career_growth        26931 non-null  float64\n",
      " 11  work_satisfaction    26909 non-null  float64\n",
      " 12  Likes                23905 non-null  object \n",
      " 13  Dislikes             23038 non-null  object \n",
      "dtypes: float64(7), object(7)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 546 rows with identical data.  This does not necessarily mean they are redundant or duplicates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 26993 rows before dropping 'Overall_rating' and 25896 rows after dropping 'Overall_rating'\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the columns Title and Overall_rating\n",
    "# Overall rating is the target column and required for classification\n",
    "# Title is almost always missing when overall rating is missing\n",
    "before_drop = len(df.index)\n",
    "df = df.dropna(subset=['Title', 'Overall_rating'])\n",
    "after_drop = len(df.index)\n",
    "print(f\"There were {before_drop} rows before dropping 'Overall_rating' and {after_drop} rows after dropping 'Overall_rating'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicates found in the dataset\n"
     ]
    }
   ],
   "source": [
    "initial_count = df.shape[0]  # Stores the initial number of rows in the DataFrame\n",
    "df_without_duplicates = df.drop_duplicates()  # Removes duplicate rows from the DataFrame\n",
    "without_duplicates_count = df_without_duplicates.shape[0]  # Stores the number of rows after removing duplicates\n",
    "print(f\"There are {initial_count-without_duplicates_count} duplicates found in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are Title                      0\n",
      "Place                   1310\n",
      "Job_type               14341\n",
      "Department              3830\n",
      "Date                       0\n",
      "Overall_rating             0\n",
      "work_life_balance         12\n",
      "skill_development         12\n",
      "salary_and_benefits       21\n",
      "job_security              22\n",
      "career_growth             30\n",
      "work_satisfaction         32\n",
      "Likes                   2004\n",
      "Dislikes                2870\n",
      "dtype: int64 duplicates.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (f\"There are {df.isnull().sum()} duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in empty values with NA\n",
    "# fix Place data\n",
    "no_place = {\n",
    "\"..\": \"na\",\n",
    "\"any location\": \"na\",\n",
    "\"any\": \"na\",\n",
    "\"any place\": \"na\",\n",
    "\"client location \": \"na\",\n",
    "\"client office\": \"na\",\n",
    "\"confidential\": \"na\",\n",
    "\"customer location\": \"na\",\n",
    "\"do not with to disclose\": \"na\",\n",
    "\"doesn\" \"t matter\": \"na\",\n",
    "\"everywhere\": \"na\",\n",
    "\"i don\" \"t know i did only internship only\": \"na\",\n",
    "\"no idea\": \"na\",\n",
    "\"office\": \"na\",\n",
    "\"somewhere\": \"na\",\n",
    "\"xyz\": \"na\",\n",
    "\"it's very good experience.\"    : 'na',\n",
    "\"i don't know i did only internship only\": \"na\"\n",
    "}\n",
    "\n",
    "outside_india = {\n",
    "    \"uk\": \"united kingdom\",\n",
    "    \"usa\": \"united states\",\n",
    "    \"sydneu\": \"sydney\",\n",
    "}\n",
    "\n",
    "bangalore = {\n",
    "   \"6b bangalore\": \"bangalore\",\n",
    "\"6b ecospace\": \"bangalore\",\n",
    "\"6b\": \"bangalore\",\n",
    "\"bagalore\": \"bangalore\",\n",
    "\"baglore\": \"bangalore\",\n",
    "\"bamgalore\": \"bangalore\",\n",
    "\"banagalore\": \"bangalore\",\n",
    "\"banaglore\": \"bangalore\",\n",
    "\"bangaloe\": \"bangalore\",\n",
    "\"bangalor\": \"bangalore\",\n",
    "\"bangalore 6b\": \"bangalore\",\n",
    "\"bangalore dtp\": \"bangalore\",\n",
    "\"bangalore epip\": \"bangalore\",\n",
    "\"bangalore rural\": \"bangalore\",\n",
    "\"bangalore urban\": \"bangalore\",\n",
    "\"bangalore whitefield\": \"bangalore\",\n",
    "\"bangalore.\": \"bangalore\",\n",
    "\"bangalore/bengaluru\": \"bangalore\",\n",
    "\"bangalores\": \"bangalore\",\n",
    "\"bangalorr\": \"bangalore\",\n",
    "\"bangaluru\": \"bangalore\",\n",
    "\"banglore bmp\": \"bangalore\",\n",
    "\"banglore datacom\": \"bangalore\",\n",
    "\"banglore whitefield\": \"bangalore\",\n",
    "\"banglore\": \"bangalore\",\n",
    "\"bbangalore\": \"bangalore\",\n",
    "\"bengalore\": \"bangalore\",\n",
    "\"bengaluru\": \"bangalore\",\n",
    "\"bengaluru/bangalore\": \"bangalore\",\n",
    "\"benglore\": \"bangalore\",\n",
    "\"benguluru\": \"bangalore\",\n",
    "\"blore\": \"bangalore\",\n",
    "\"blr\": \"bangalore\",\n",
    "\"capgemini bangalore\": \"bangalore\",\n",
    "\"dtp bangalore\": \"bangalore\",\n",
    "\"dtp\": \"bangalore\",\n",
    "\"whietfield\": \"bangalore\",\n",
    "\"whiltefield\": \"bangalore\",\n",
    "\"whiltefield\": \"bangalore\",\n",
    "\"white feeld\": \"bangalore\",\n",
    "\"white field dtp\": \"bangalore\",\n",
    "\"white field summit towers a\": \"bangalore\",\n",
    "\"white field\": \"bangalore\",\n",
    "\"White Filed\": \"bangalore\",\n",
    "\"white filed\": \"bangalore\",\n",
    "\"whitefield bangalore\": \"bangalore\",\n",
    "\"whitefield\": \"bangalore\",\n",
    "\"whitefiled\": \"bangalore\",\n",
    "\"whitfield\": \"bangalore\",\n",
    "}\n",
    "\n",
    "rest_of_india = {\n",
    "    \"hyderabad/secunderabad\": \"hyderabad\",\n",
    "    \"hyderbad\": \"hyderabad\",\n",
    "    \"hydrabad\": \"hyderabad\",\n",
    "    \"hyder\": \"hyderabad\",\n",
    "    \"hyd\": \"hyderabad\",\n",
    "    \"navi mumbai\": \"mumbai\",\n",
    "    \"mumbai suburban\": \"mumbai\",\n",
    "    \"airoli mumbai\": \"mumbai\",\n",
    "    \"mumbai airoli\": \"mumbai\",\n",
    "    \"airoli navi mumbai\": \"mumbai\",\n",
    "    \"airloi\": \"mumbai\",\n",
    "    \"airoli sez\": \"mumbai\",\n",
    "    \"airloi\": \"mumbai\",\n",
    "    \"airoli,mumbai\": \"mumbai\",\n",
    "    \"airoli,navi mumbai\": \"mumbai\",\n",
    "    \"airolo\": \"mumbai\",\n",
    "    \"airoli sez\": \"mumbai\",\n",
    "    \"airoli west\": \"mumbai\",\n",
    "    \"airoli,maharashtra\": \"mumbai\",\n",
    "    \"airolo\": \"mumbai\",\n",
    "    \"airoil mumbai\": \"mumbai\",\n",
    "    \"airoli yosemite\": \"mumbai\",\n",
    "    \"airoli mindspace\": \"mumbai\",\n",
    "    \"airolii\": \"mumbai\",\n",
    "    \"aeroli\": \"mumbai\",\n",
    "    \"airoli mindspace\": \"mumbai\",\n",
    "    \"new mumbai\": \"mumbai\",\n",
    "    \"vikhroli\": \"vikhroli\",\n",
    "    \"vikhroli - mumbai\": \"vikhroli\",\n",
    "    \"vikhroli east\": \"vikhroli\",\n",
    "    \"vikhroli,mumbai and airoli\": \"vikhroli\",\n",
    "    \"vikroli\": \"vikhroli\",\n",
    "    \"vikroholi\": \"vikhroli\",\n",
    "    \"vikhroli office\": \"vikhroli\",\n",
    "    \"vikhroli mumbai\": \"vikhroli\",\n",
    "    \"vikhroli,mumbai\": \"vikhroli\",\n",
    "    \"vikhrolli\": \"vikhroli\",\n",
    "    \"vikhrolli\": \"vikhroli\",\n",
    "    \"gurgaon/gurugram\": \"gurgaon\",\n",
    "    \"gurugram\": \"gurgaon\",\n",
    "    \"greater noida\": \"noida\",\n",
    "    \"noida nsez\": \"noida\",\n",
    "    \"nsez noida\": \"noida\",\n",
    "    \"nsez\": \"noida\",\n",
    "    \"noida sez\": \"noida\",\n",
    "    \"new delhi\": \"delhi\",\n",
    "    \"delhi ncr\": \"delhi\",\n",
    "    \"talwade pune\": \"pune\",\n",
    "    \"pune talwade\": \"pune\",\n",
    "    \"punr\": \"pune\",\n",
    "    \"hinjewadi pune\": \"pune\",\n",
    "    \"pune hinjewadi\": \"pune\",\n",
    "    \"chenani\": \"chennai\",\n",
    "    \"trichy\": \"tiruchirappalli\",\n",
    "    \"tiruchirapalli\": \"tiruchirappalli\",\n",
    "    \"tiruchuli\": \"tiruchirappalli\",\n",
    "    \"selam\": \"salem\",\n",
    "    \"yasomite airoli\": \"yosemite airoli\",\n",
    "\n",
    "    \"wfh (working remotely)\": \"remote\",\n",
    "    \"work from home (working remotely)\": \"remote\",\n",
    "    \"remote (working remotely)\": \"remote\",\n",
    "    \"remotely\": \"remote\",\n",
    "    \"although i am still working from home so it depends project to project\": \"remote\",\n",
    "    \"home\": \"remote\",\n",
    "    \"no i work from home only during vivid 29\": \"remote\",\n",
    "    \"trich\": \"tiruchirapalli\",\n",
    "    \"trichirapalli\": \"tiruchirapalli\",\n",
    "    \"trichy,vrn\": \"tiruchirapalli\",\n",
    "    \"trichirapalli\": \"tiruchirapalli\",\n",
    "    \"trichirappalli\": \"tiruchirapalli\",\n",
    "    \"talawade\": \"pune\",\n",
    "    \"talwade\": \"pune\",\n",
    "    \"pu ne\": \"pune\",\n",
    "    \"pu e\": \"pune\",\n",
    "    \"pu\": \"pune\",\n",
    "    \"talvade pune\": \"pune\",\n",
    "    \"talwadde\": \"pune\",\n",
    "    \"talawde\": \"pune\",\n",
    "    \"pune,talawade\": \"pune\",\n",
    "    \"talawade,pune\": \"pune\",\n",
    "    \"pube\": \"pune\",\n",
    "    \"talwade,pune\": \"pune\",\n",
    "    \"talawade pune\": \"pune\",\n",
    "    \"talwade pune. depend it\" \"s chandes\": \"pune\",\n",
    "}\n",
    "\n",
    "all_places = no_place | outside_india | bangalore | rest_of_india\n",
    "\n",
    "\n",
    "df[\"Place\"] = df[\"Place\"].fillna(\"na\").apply(lambda x: x.lower().split(\", \")[0])\n",
    "df[\"Place\"] = df[\"Place\"].replace(all_places)\n",
    "\n",
    "# where Place is NA and titla contains the phrase \"Remotely\" we can assume they work remotely for their Place.\n",
    "def isRemoteTitle(title, place):\n",
    "    if \"na\" == place and \"Remotely\".casefold() in title.casefold():\n",
    "        return \"remote\"\n",
    "    else:\n",
    "        return place\n",
    "df[\"Place\"] = df.apply(lambda x: isRemoteTitle(x.Title, x.Place), axis=1)        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Dates\n",
    "\n",
    "def get_date(x):\n",
    "    try:\n",
    "        return str(x)[2:]\n",
    "    except:\n",
    "        return 'None'\n",
    "df['Date'] = df['Date'].fillna('0 None').apply(get_date)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%b %Y\",  errors='raise')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ratings as categorical data\n",
    "from pandas import CategoricalDtype\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "rating_columns = ['Overall_rating', 'work_life_balance', 'skill_development', 'salary_and_benefits', 'job_security', 'career_growth', 'work_satisfaction']\n",
    "\n",
    "# use SimpleImputer to fill missing values for columnn Overall_rating with the most frequent value\n",
    "for column in rating_columns:\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[column] = imputer.fit_transform(df[[column]])\n",
    "    df[column] = df[column].astype('int32')\n",
    "\n",
    "rating_categories = CategoricalDtype(categories=[1, 2, 3, 4, 5], ordered=True)\n",
    "\n",
    "for column in rating_columns:\n",
    "    df[column] = df[column].astype(rating_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set job_type\n",
    "from pandas import CategoricalDtype\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "job_type_columns = ['Job_type']\n",
    "\n",
    "# use SimpleImputer to fill missing values for columnn Overall_rating with the most frequent value\n",
    "for column in job_type_columns:\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[column] = imputer.fit_transform(df[[column]])\n",
    "    df[column] = df[column].astype('string')\n",
    "\n",
    "job_type_categories = CategoricalDtype(categories=['Contractual', 'Freelancer', 'Full Time', 'Intern', 'Part Time'])\n",
    "\n",
    "for column in job_type_columns:\n",
    "    df[column] = df[column].astype(job_type_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set rest of columns as strings\n",
    "string_columns = ['Title', 'Place', 'Department', 'Likes', 'Dislikes']\n",
    "\n",
    "for column in string_columns:\n",
    "    df[column] = df[column].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25896 entries, 0 to 26975\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Title                25896 non-null  string        \n",
      " 1   Place                25896 non-null  string        \n",
      " 2   Job_type             25896 non-null  category      \n",
      " 3   Department           22066 non-null  string        \n",
      " 4   Date                 25896 non-null  datetime64[ns]\n",
      " 5   Overall_rating       25896 non-null  category      \n",
      " 6   work_life_balance    25896 non-null  category      \n",
      " 7   skill_development    25896 non-null  category      \n",
      " 8   salary_and_benefits  25896 non-null  category      \n",
      " 9   job_security         25896 non-null  category      \n",
      " 10  career_growth        25896 non-null  category      \n",
      " 11  work_satisfaction    25896 non-null  category      \n",
      " 12  Likes                23892 non-null  string        \n",
      " 13  Dislikes             23026 non-null  string        \n",
      "dtypes: category(8), datetime64[ns](1), string(5)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "df.to_csv(\"data/after prep.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
